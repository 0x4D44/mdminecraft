# Stage 3 Implementation Plan — Networking & Multiplayer Surfaces
Date: 2025-11-14

## Executive Summary

**Stage 2 Completion Status:** ✅ All phases complete (Lighting, Day/Night, Weather, Persistence, Inventory, Crafting)

**Stage 3 Objectives:** Implement server-authoritative netcode with QUIC transport, client prediction/reconciliation, chunk streaming with delta compression, and deterministic replay plumbing.

**Timeline:** Weeks 13-18 (6 weeks, Nov 14 - Dec 26, 2025)

**Key Deliverables:**
- QUIC transport layer with quinn
- Postcard protocol with versioning and schema hash
- Client prediction + reconciliation with rewind/replay
- Chunk delta compression (palette + RLE)
- Entity delta replication
- Deterministic replay harness with input logs
- Two-player LAN worldtest scenario

---

## Stage 3 Architecture Overview

### Network Stack Layers
```
┌─────────────────────────────────────────────────────┐
│  Client Application (Input, Rendering, HUD)        │
├─────────────────────────────────────────────────────┤
│  Client Prediction (Local ECS Schedule)            │
├─────────────────────────────────────────────────────┤
│  Reconciliation (Rewind/Replay on Mismatch)        │
├─────────────────────────────────────────────────────┤
│  Protocol Layer (Postcard Messages + Schema Hash)  │
├─────────────────────────────────────────────────────┤
│  QUIC Transport (Quinn over UDP + TLS)             │
└─────────────────────────────────────────────────────┘
                         ↕
┌─────────────────────────────────────────────────────┐
│  QUIC Transport (Quinn over UDP + TLS)             │
├─────────────────────────────────────────────────────┤
│  Protocol Layer (Postcard Messages + Schema Hash)  │
├─────────────────────────────────────────────────────┤
│  Server ECS (Authoritative Simulation)             │
├─────────────────────────────────────────────────────┤
│  Server Application (World, Physics, Entities)     │
└─────────────────────────────────────────────────────┘
```

### Message Channels
1. **Input Channel** (Client → Server, Unreliable ordered)
   - Player input bundles tagged with last acknowledged tick
   - Movement, block interactions, inventory operations

2. **ChunkStream Channel** (Server → Client, Reliable ordered)
   - Delta-compressed chunk data (palette + RLE)
   - Chunk unload notifications

3. **EntityDelta Channel** (Server → Client, Unreliable ordered)
   - Transform updates (position, rotation)
   - Component updates (health, inventory slots)

4. **Chat Channel** (Bidirectional, Reliable ordered)
   - Text messages
   - System notifications

5. **Diagnostics Channel** (Bidirectional, Reliable ordered)
   - Metrics, debug info
   - Server commands (admin/testkit)

---

## Phase 3.1: QUIC Transport Foundation (Priority 1)

**Objective:** Implement QUIC transport layer using quinn with connection management, channel multiplexing, and basic handshake.

### Tasks

#### 1. Transport Layer Setup (Days 1-2)
- Add quinn workspace dependencies (quinn 0.11+, rustls, rcgen for TLS)
- Create `crates/net/src/transport.rs` with QUIC connection abstraction
- Implement server endpoint: bind UDP socket, configure TLS with self-signed certs
- Implement client endpoint: connect to server with TLS validation (allow self-signed for dev)
- **Acceptance:** Client can connect to server, establish QUIC connection

#### 2. Channel Multiplexing (Days 3-4)
- Create `crates/net/src/channel.rs` with channel types enum
- Implement reliable ordered channels (QUIC streams)
- Implement unreliable ordered channels (QUIC datagrams)
- Add channel routing: map message types to appropriate channels
- **Acceptance:** Multiple message types can be sent/received on correct channels

#### 3. Connection Management (Day 5)
- Add connection lifecycle: Connect → Handshake → Active → Disconnect
- Implement timeout detection (no packets for 10s → disconnect)
- Add reconnection logic with exponential backoff
- Emit connection events: Connected, Disconnected, TimedOut
- **Acceptance:** Graceful disconnect, timeout detection, reconnection working

#### 4. Integration with Server/Client Crates (Days 6-7)
- Update `crates/server/src/lib.rs` to host QUIC endpoint
- Update `crates/client/src/lib.rs` to connect via QUIC
- Add NetworkResource to ECS for server and client
- Wire connection events into event bus
- **Acceptance:** Server accepts connections, client connects, events logged

### Deliverables
- `crates/net/src/transport.rs` (~250 lines)
- `crates/net/src/channel.rs` (~150 lines)
- `crates/net/src/connection.rs` (~200 lines)
- Unit tests: `tests/transport_handshake.rs` (~80 lines)
- Integration test: client connects to server, sends ping, receives pong

### Exit Criteria
- ✅ QUIC connection established with TLS encryption
- ✅ Multiple channels multiplexed over single connection
- ✅ Connection lifecycle managed with timeouts and reconnection
- ✅ Events emitted for connection state changes
- ✅ Unit tests pass, integration test shows successful ping/pong

---

## Phase 3.2: Protocol Schema & Messages (Priority 2)

**Objective:** Define postcard-based message protocol with versioning, schema hashing, and type-safe message definitions.

### Tasks

#### 1. Message Type Definitions (Days 1-2)
- Create `crates/net/src/protocol.rs` with message enums
- Define ClientMessage: InputBundle, ChatMessage, DiagnosticsRequest
- Define ServerMessage: ChunkData, EntityDelta, ChatMessage, ServerState
- Add Serialize/Deserialize derives using postcard-friendly types
- **Acceptance:** All message types serialize/deserialize with postcard

#### 2. Schema Versioning (Days 3-4)
- Add PROTOCOL_VERSION constant and PROTOCOL_MAGIC bytes
- Compute schema hash from message type definitions (blake3)
- Add handshake message: client sends version+hash, server validates
- Reject connections on version/hash mismatch with clear error
- **Acceptance:** Schema mismatch detected and rejected during handshake

#### 3. Message Encoding/Decoding (Day 5)
- Implement frame format: `[length: u32][message_type: u8][payload: bytes]`
- Add encode() and decode() helpers with length prefixing
- Add message batching: multiple messages in single frame (optimization)
- **Acceptance:** Messages encode/decode correctly, batch optimization works

#### 4. Input Bundle Protocol (Days 6-7)
- Define InputBundle message with tick, actions, and sequence number
- Actions: Movement (forward/back/left/right/jump), BlockInteract, InventoryOp
- Add last_ack_tick field for client to confirm server state
- Implement input compression: delta encoding for movement vectors
- **Acceptance:** Input bundles encode efficiently, delta compression working

### Deliverables
- `crates/net/src/protocol.rs` (~300 lines)
- `crates/net/src/message.rs` (~200 lines)
- `crates/net/src/codec.rs` (~150 lines)
- Unit tests: `tests/protocol_codec.rs` (~100 lines)
- Schema hash computed and validated during handshake

### Exit Criteria
- ✅ All message types defined with Serialize/Deserialize
- ✅ Protocol version and schema hash validated during handshake
- ✅ Message encoding/decoding working with length prefixing
- ✅ Input bundles efficiently encoded with delta compression
- ✅ Schema mismatch detection prevents incompatible clients

---

## Phase 3.3: Client Prediction & Reconciliation (Priority 3)

**Objective:** Implement client-side prediction with local ECS schedule, server reconciliation via rewind/replay on mismatch.

### Tasks

#### 1. Client Prediction Schedule (Days 1-3)
- Create trimmed ECS schedule for client: InputIngest → Physics → MinimalWorldView
- Add predicted entities with client-side components: PredictedTransform
- Implement input buffering: store last N inputs with tick numbers
- Run prediction schedule locally without waiting for server
- **Acceptance:** Client movement feels responsive, no input lag

#### 2. Server State Updates (Days 4-5)
- Implement server tick updates: authoritative transform + tick number
- Client receives server state for player entity and nearby entities
- Store server state snapshots in circular buffer (last 60 ticks = 3 seconds)
- Compare predicted state vs server state at matching tick
- **Acceptance:** Client receives and stores server state snapshots

#### 3. Reconciliation via Rewind/Replay (Days 6-8)
- Detect mismatch: predicted position differs from server by >threshold (0.5 blocks)
- Rewind: restore game state to server tick
- Replay: re-apply buffered inputs from server tick to current tick
- Emit ReconciliationEvent with error magnitude for metrics
- **Acceptance:** Position corrections smooth, reconciliation events logged

#### 4. Interpolation for Remote Entities (Days 9-10)
- Implement entity interpolation: smooth movement between server snapshots
- Use interpolation delay (100ms = 2 ticks) to ensure smooth motion
- Add InterpTransform component for remote entities
- Lerp position and slerp rotation between snapshots
- **Acceptance:** Remote players move smoothly without jitter

### Deliverables
- `crates/client/src/prediction.rs` (~250 lines)
- `crates/client/src/reconciliation.rs` (~200 lines)
- `crates/client/src/interpolation.rs` (~150 lines)
- Unit tests: `tests/prediction_reconciliation.rs` (~120 lines)
- Metrics: reconciliation error magnitude and frequency

### Exit Criteria
- ✅ Client prediction provides immediate input response
- ✅ Server state reconciliation corrects divergence smoothly
- ✅ Rewind/replay logic restores correct state after mismatch
- ✅ Remote entities interpolated smoothly with <100ms delay
- ✅ Reconciliation events logged with error magnitudes
- ✅ Average reconciliation error <=30ms at 100ms RTT

---

## Phase 3.4: Chunk Streaming & Delta Compression (Priority 4)

**Objective:** Implement chunk streaming with delta compression (palette + RLE) to efficiently transmit world data to clients.

### Tasks

#### 1. Chunk Delta Compression (Days 1-3)
- Create `crates/net/src/chunk_encoding.rs` for compression
- Implement palette-based encoding: unique block IDs → palette indices
- Implement RLE compression on palette indices for repeated blocks
- Add zstd compression on encoded data for additional savings
- **Acceptance:** Chunk compression achieves >80% size reduction on typical terrain

#### 2. Chunk Streaming Protocol (Days 4-5)
- Define ChunkData message with position, palette, RLE data, and CRC
- Implement chunk priority: distance from player → send nearest first
- Add chunk load/unload messages based on view distance
- Track client chunk subscriptions on server
- **Acceptance:** Chunks stream to client based on distance priority

#### 3. Client Chunk Assembly (Days 6-7)
- Implement chunk decoding: decompress, expand RLE, apply palette
- Reconstruct chunk from encoded data and insert into ChunkStorage
- Mark chunk as DIRTY_MESH to trigger meshing
- Emit ChunkLoaded event for client rendering
- **Acceptance:** Client receives and reconstructs chunks correctly

#### 4. Bandwidth Optimization (Days 8-9)
- Implement chunk diff encoding: send only changed voxels for updates
- Add throttling: limit bandwidth to target cap (e.g., 1 MB/s per client)
- Track metrics: bytes sent, compression ratio, chunk load time
- Optimize update frequency: send chunk updates every 5 ticks (250ms)
- **Acceptance:** Bandwidth within target cap, metrics tracked

### Deliverables
- `crates/net/src/chunk_encoding.rs` (~300 lines)
- `crates/net/src/chunk_streaming.rs` (~250 lines)
- `crates/client/src/chunk_assembly.rs` (~150 lines)
- Unit tests: `tests/chunk_compression.rs` (~80 lines)
- Metrics: compression ratio, bandwidth usage, chunk load times

### Exit Criteria
- ✅ Chunk compression achieves >80% size reduction
- ✅ Chunks stream based on distance priority
- ✅ Client reconstructs chunks correctly from encoded data
- ✅ Bandwidth throttled to target cap per client
- ✅ Chunk updates use diff encoding for efficiency
- ✅ Metrics tracked: bytes sent, compression ratio, load times

---

## Phase 3.5: Entity Delta Replication (Priority 5)

**Objective:** Replicate entity state (transforms, health, inventory) from server to clients using delta encoding.

### Tasks

#### 1. Entity State Tracking (Days 1-2)
- Create `crates/net/src/entity_replication.rs` for entity tracking
- Track entity visibility: which entities are in view distance of each client
- Maintain per-client entity state snapshots for delta encoding
- Add entity spawn/despawn messages
- **Acceptance:** Server tracks visible entities per client

#### 2. Delta Encoding (Days 3-4)
- Implement delta encoding for Transform: send only changed fields
- Use quantization: positions to 1/16 block precision, rotation to 256 steps
- Encode health, velocity, and other components with delta compression
- Batch entity updates into single message per tick
- **Acceptance:** Entity updates efficiently delta-encoded

#### 3. Entity Update Messages (Day 5)
- Define EntityDelta message: entity_id, tick, component updates
- Send entity updates at 10 Hz (every other tick) to reduce bandwidth
- Prioritize entity updates by distance and change magnitude
- **Acceptance:** Entity updates sent efficiently with prioritization

#### 4. Client Entity Reconstruction (Days 6-7)
- Client receives entity deltas and applies to local entities
- Create missing entities from spawn messages
- Remove entities from despawn messages
- Update interpolation targets for remote entities
- **Acceptance:** Client entities synchronized with server state

### Deliverables
- `crates/net/src/entity_replication.rs` (~250 lines)
- `crates/net/src/entity_delta.rs` (~200 lines)
- `crates/client/src/entity_sync.rs` (~150 lines)
- Unit tests: `tests/entity_delta.rs` (~80 lines)
- Metrics: entity update rate, delta compression ratio

### Exit Criteria
- ✅ Entities tracked per client based on view distance
- ✅ Delta encoding reduces entity update bandwidth by >60%
- ✅ Entity updates prioritized by distance and change magnitude
- ✅ Client entities synchronized with server authoritative state
- ✅ Spawn/despawn messages handled correctly
- ✅ Metrics tracked: update rate, compression ratio

---

## Phase 3.6: Deterministic Replay Harness (Priority 6)

**Objective:** Extend testkit replay system to capture input logs and network events, enabling deterministic replay with server diff comparison.

### Tasks

#### 1. Input Log Capture (Days 1-2)
- Extend testkit to capture InputBundle messages to JSONL
- Record input timing: tick number, sequence, actions
- Store input logs alongside event stream in testkit output
- **Acceptance:** Input logs captured during gameplay sessions

#### 2. Network Event Logging (Days 3-4)
- Add network events to event stream: Connected, Disconnected, ReconciliationEvent
- Log server state snapshots at key ticks for diff comparison
- Capture chunk stream events: ChunkLoaded, ChunkUnloaded
- **Acceptance:** Network events logged to JSONL event stream

#### 3. Replay Playback (Days 5-7)
- Implement replay mode: load input log, feed to headless client
- Client connects to server, replays inputs from log
- Capture authoritative server event stream during replay
- Compare replay event stream with original golden event stream
- **Acceptance:** Replay produces deterministic event stream

#### 4. Diff Validation (Days 8-9)
- Implement event stream diff tool: compare two JSONL files
- Detect schema drift: version mismatches, missing events
- Report differences: missing events, ordering changes, value mismatches
- Fail CI if diff detects non-deterministic behavior
- **Acceptance:** Diff tool detects and reports event stream differences

### Deliverables
- `crates/testkit/src/input_log.rs` (~150 lines)
- `crates/testkit/src/replay.rs` (~200 lines)
- `crates/testkit/src/diff.rs` (~180 lines)
- Integration test: `tests/replay_determinism.rs` (~100 lines)
- CI integration: replay diff check in workflow

### Exit Criteria
- ✅ Input logs captured during gameplay and replay
- ✅ Network events logged to JSONL event stream
- ✅ Replay mode produces deterministic event stream
- ✅ Diff tool detects schema drift and event mismatches
- ✅ CI validates replay determinism with zero drift warnings
- ✅ Replay event stream matches authoritative server record

---

## Phase 3.7: LAN Worldtest Scenario (Priority 7)

**Objective:** Create two-player LAN worldtest scenario demonstrating multiplayer functionality with metrics validation.

### Tasks

#### 1. LAN Test Infrastructure (Days 1-2)
- Create `tests/lan_multiplayer.rs` worldtest scenario
- Spawn server with superflat world
- Spawn two clients: connect, join game
- **Acceptance:** Two clients successfully connect to server

#### 2. Collaborative Building Test (Days 3-4)
- Script actions: Client 1 places blocks, Client 2 observes
- Validate: Client 2 sees blocks placed by Client 1
- Script actions: Client 2 breaks blocks, Client 1 observes
- Validate: Client 1 sees blocks removed by Client 2
- **Acceptance:** Block changes replicated between clients

#### 3. Movement and Entity Sync Test (Day 5)
- Script actions: Client 1 moves around, Client 2 observes
- Validate: Client 2 sees Client 1's movement interpolated smoothly
- Add simulated 100ms RTT network latency
- Measure reconciliation error and frequency
- **Acceptance:** Entity movement synchronized with <30ms error

#### 4. Metrics Collection and Validation (Days 6-7)
- Collect metrics: bandwidth per client, reconciliation errors, chunk load times
- Validate: bandwidth within cap, reconciliation errors <=30ms avg
- Capture event streams from server and both clients
- Validate: event streams match authoritative server record
- **Acceptance:** Metrics within targets, event streams deterministic

### Deliverables
- `tests/lan_multiplayer.rs` (~200 lines)
- `tests/fixtures/lan_scenario.toml` (~50 lines)
- Metrics dashboard: bandwidth, RTT, reconciliation errors
- CI integration: LAN worldtest as blocking job

### Exit Criteria
- ✅ Two clients connect to server and join game
- ✅ Block changes replicated between clients
- ✅ Entity movement synchronized with <30ms error at 100ms RTT
- ✅ Bandwidth per client within target cap
- ✅ Event streams match server authoritative record
- ✅ Deterministic replay diff clean with zero drift warnings
- ✅ LAN worldtest passes in CI as blocking job

---

## Stage 3 Exit Criteria Summary

Before proceeding to Stage 4 (Biomes & Content), verify:

- ✅ **QUIC Transport:** Connection established, channels multiplexed, lifecycle managed
- ✅ **Protocol:** Postcard messages with versioning, schema hash validated
- ✅ **Client Prediction:** Immediate input response, smooth reconciliation
- ✅ **Chunk Streaming:** Delta compression >80%, bandwidth within cap
- ✅ **Entity Replication:** Delta encoding >60% savings, synchronized state
- ✅ **Replay Harness:** Input logs captured, event streams deterministic
- ✅ **LAN Worldtest:** Two-player scenario passing, metrics within targets
- ✅ **Performance:** <=30ms avg reconciliation error at 100ms RTT
- ✅ **Bandwidth:** Peak bandwidth per client within specified cap
- ✅ **Determinism:** Event streams match server record, zero drift warnings
- ✅ **CI:** All networking tests passing, LAN worldtest blocking job green

**Acceptance Gate:** QA sign-off on LAN worldtest (two-player building), replay diff clean, metrics within targets, no warnings in event logs.

---

## Risk Assessment & Mitigation

| Risk | Probability | Impact | Mitigation |
|------|-------------|--------|------------|
| **QUIC Connection Instability** | MEDIUM | HIGH | Implement robust timeout detection; exponential backoff reconnection; test with simulated packet loss |
| **Reconciliation Jitter** | MEDIUM | MEDIUM | Tune interpolation delay; optimize rewind/replay performance; profile client tick budget |
| **Bandwidth Exceeds Cap** | MEDIUM | HIGH | Implement aggressive chunk compression; throttle update rates; prioritize nearby chunks/entities |
| **Schema Drift in Replay** | LOW | CRITICAL | Validate schema hash at handshake; version all messages; fail fast on mismatch |
| **Non-Deterministic Replay** | LOW | CRITICAL | Audit for wall-clock usage; ensure all RNG seeded; add replay diff to CI |
| **Client Prediction Divergence** | MEDIUM | MEDIUM | Implement sanity checks; limit prediction window; log large reconciliation errors |

**Contingency:** If any Phase 3.x slips >2 days, escalate for scope adjustment. Defer advanced features (e.g., voice chat) to later stages if needed.

---

## Timeline & Milestones

| Week | Phase | Milestone |
|------|-------|-----------|
| 13 | 3.1 | QUIC transport operational, handshake working |
| 14 | 3.2 | Protocol schema defined, messages encode/decode |
| 15 | 3.3 | Client prediction + reconciliation functional |
| 16 | 3.4 | Chunk streaming with delta compression working |
| 17 | 3.5-3.6 | Entity replication + replay harness complete |
| 18 | 3.7 | LAN worldtest passing, metrics validated |

**Target Completion:** Week 18 (Dec 26, 2025)

---

## Success Metrics

Track the following in `metrics.json` and CI artifacts:

| Metric | Target | Measurement |
|--------|--------|-------------|
| **Connection Latency** | <=50ms handshake time | Transport timing in connection.rs |
| **Reconciliation Error** | <=30ms avg at 100ms RTT | ReconciliationEvent magnitudes |
| **Chunk Compression** | >80% size reduction | Compression ratio in chunk_encoding.rs |
| **Bandwidth per Client** | <=1 MB/s peak | Network throughput metrics |
| **Entity Update Rate** | 10 Hz (every 2 ticks) | Entity delta message timing |
| **Replay Determinism** | 0 drift warnings | Event stream diff validation |
| **LAN Worldtest Pass Rate** | 100% in CI | CI test results |

**Dashboard:** Export weekly metrics to `metrics/stage3_weekly.json` for trend analysis.

---

## Post-Stage 3 Outlook

**Stage 4 Preview (Weeks 19-24):**
- Biome noise stack and procedural terrain generation
- Structure placement (trees, caves, villages)
- Passive mob AI with deterministic FSM
- Weather toggle UI and visual effects
- Performance baselines (MegaForest, CaveCity scenarios)

**Stage 3 → Stage 4 Handoff Requirements:**
- Networking stable and deterministic (no desync issues)
- Chunk streaming optimized for terrain generation load
- Entity replication supports mob AI state
- Performance baselines documented for comparison with content load

---

## Quick Reference

**Key Files for Stage 3 Work:**
- `/crates/net/src/transport.rs` (NEW — Phase 3.1)
- `/crates/net/src/channel.rs` (NEW — Phase 3.1)
- `/crates/net/src/protocol.rs` (NEW — Phase 3.2)
- `/crates/net/src/chunk_encoding.rs` (NEW — Phase 3.4)
- `/crates/client/src/prediction.rs` (NEW — Phase 3.3)
- `/crates/client/src/reconciliation.rs` (NEW — Phase 3.3)
- `/crates/testkit/src/replay.rs` (MODIFY — Phase 3.6)

**Test Files to Create:**
- `/tests/transport_handshake.rs`
- `/tests/protocol_codec.rs`
- `/tests/prediction_reconciliation.rs`
- `/tests/chunk_compression.rs`
- `/tests/entity_delta.rs`
- `/tests/replay_determinism.rs`
- `/tests/lan_multiplayer.rs`

**Documentation to Update:**
- `/wrk_journals/2025.11.14 - JRN - Stage 3 Buildout.md` (NEW)
- `/wrk_docs/2025.11.12 - HLD - Deterministic Voxel Sandbox.md` (update networking sections)
- `/wrk_docs/2025.11.12 - PLN - Deterministic Voxel Sandbox Implementation.md` (mark Stage 3 started)

**Commit Message Convention:**
- `[Stage3] Implement QUIC transport with quinn`
- `[Stage3] Add client prediction and reconciliation`
- `[Stage3] Wire chunk streaming with delta compression`

---

## Conclusion

**Stage 2 Status:** ✅ **COMPLETE** — All phases delivered, 36 tests passing.

**Stage 3 Readiness:** ✅ **READY TO PROCEED** — All Stage 2 deliverables verified, networking foundation scaffolded.

**Next Action:** Initialize `/wrk_journals/2025.11.14 - JRN - Stage 3 Buildout.md` and begin Phase 3.1 (QUIC Transport Foundation).

**Estimated Timeline:** Stage 3 completion target: Week 18 (6 weeks from kickoff, per original plan).

**Confidence Level:** HIGH — Strong foundation from Stages 1-2, quinn crate mature, deterministic architecture validated.

---

**Prepared by:** Claude (AI Assistant)
**Date:** 2025-11-14
**Document Version:** 1.0
**Review Status:** Pending stakeholder sign-off
