# Worldtest Usage Guide

**Date:** 2025-11-15
**Version:** Stage 5.3
**Purpose:** Comprehensive guide for running, writing, and understanding worldtests

---

## Table of Contents

1. [Overview](#overview)
2. [What are Worldtests?](#what-are-worldtests)
3. [Running Worldtests](#running-worldtests)
4. [Available Worldtests](#available-worldtests)
5. [Writing New Worldtests](#writing-new-worldtests)
6. [Metrics Integration](#metrics-integration)
7. [CI/CD Integration](#cicd-integration)
8. [Performance Expectations](#performance-expectations)
9. [Troubleshooting](#troubleshooting)

---

## Overview

Worldtests are large-scale integration tests that validate entire subsystems working together in realistic scenarios. Unlike unit tests (which test isolated components) or integration tests (which test component interactions), worldtests simulate actual gameplay scenarios at scale.

**Key Characteristics:**
- **Headless:** No GPU or rendering required
- **Deterministic:** Same seed produces identical results
- **Scalable:** Test from hundreds to thousands of chunks
- **Comprehensive:** Validate multiple subsystems simultaneously
- **Metrics-driven:** Export standardized performance data

---

## What are Worldtests?

### Purpose

Worldtests serve three primary purposes:

1. **Validation:** Ensure systems work correctly at scale
2. **Performance:** Measure and track performance metrics
3. **Regression Detection:** Catch performance degradation early

### Scope

Each worldtest focuses on a specific aspect of the engine:

| Worldtest | Primary Focus | Secondary Validations |
|-----------|--------------|----------------------|
| Large-Scale Terrain | Terrain generation at scale | Seam continuity, biome distribution, determinism |
| Persistence Round-Trip | Save/load fidelity | Compression, region files, data integrity |
| Mob Lifecycle | Mob AI and simulation | Spawning, movement, performance |
| Determinism Validation | Reproducibility | Order independence, cross-run consistency |
| Stage 4 Metrics | Integration | All subsystems working together |

### Design Philosophy

Worldtests follow these principles:

- **Single Responsibility:** Each test validates one primary concern
- **Self-Contained:** No external dependencies (files, network, etc.)
- **Fast Enough:** Complete in seconds to minutes, not hours
- **Actionable:** Failures clearly indicate what broke
- **Measurable:** Export metrics for tracking over time

---

## Running Worldtests

### Running All Worldtests

```bash
# Run all worldtests in the world crate
cargo test --package mdminecraft-world --test '*worldtest' -- --nocapture

# Run all tests including worldtests
cargo test --all
```

### Running Individual Worldtests

```bash
# Large-scale terrain generation
cargo test --package mdminecraft-world --test large_scale_terrain_worldtest -- --nocapture

# Persistence round-trip
cargo test --package mdminecraft-world --test persistence_roundtrip_worldtest -- --nocapture

# Mob lifecycle simulation
cargo test --package mdminecraft-world --test mob_lifecycle_worldtest -- --nocapture

# Determinism validation
cargo test --package mdminecraft-world --test determinism_worldtest -- --nocapture

# Stage 4 integration
cargo test --package mdminecraft-world --test stage4_metrics_worldtest -- --nocapture
```

### Running with Custom Configuration

Worldtests use constants for configuration. To modify:

1. Edit the test file directly (e.g., `crates/world/tests/large_scale_terrain_worldtest.rs`)
2. Adjust constants at the top:
   ```rust
   const WORLD_SEED: u64 = 99887766;
   const CHUNK_RADIUS: i32 = 25; // Adjust for different scales
   const MAX_SEAM_DIFF: i32 = 20;
   ```
3. Run the test

### Parallel Execution

By default, Cargo runs tests in parallel. For worldtests:

```bash
# Run sequentially (if memory constrained)
cargo test --package mdminecraft-world --test '*worldtest' -- --test-threads=1 --nocapture

# Run with specific parallelism
cargo test --package mdminecraft-world --test '*worldtest' -- --test-threads=2 --nocapture
```

---

## Available Worldtests

### 1. Large-Scale Terrain Worldtest

**File:** `crates/world/tests/large_scale_terrain_worldtest.rs`
**Duration:** ~15 seconds
**Scale:** 2,601 chunks (51×51 grid)

**What it validates:**
- Terrain generation performance at scale
- Seam continuity across all chunk boundaries
- Biome distribution and diversity
- Deterministic generation (subset verification)

**Key metrics:**
- Chunks per second
- Average/min/max generation time
- Seam validation (81,600 seams)
- Unique biomes found

**When to run:**
- After terrain generation changes
- Before releases
- Weekly regression testing

**Expected results:**
```
Chunks: 2,601
Avg generation: ~4-5ms/chunk
Seam pass rate: 100%
Max seam diff: ≤20 blocks
Unique biomes: ≥5
```

### 2. Persistence Round-Trip Worldtest

**File:** `crates/world/tests/persistence_roundtrip_worldtest.rs`
**Duration:** ~160 seconds
**Scale:** 81 chunks (9×9 grid)

**What it validates:**
- Chunk serialization correctness
- Region file format integrity
- Compression effectiveness (zstd)
- Data fidelity (100% exact match required)
- Save/load performance
- Region file reloading

**Key metrics:**
- Compression ratio (target: >3×)
- Data fidelity percentage
- Average save/load times
- Bytes written/read

**When to run:**
- After persistence system changes
- After chunk format modifications
- Before releases

**Expected results:**
```
Data fidelity: 100.000000%
Compression: 400-500×
Save/load: <1000ms/chunk
Region files: Multiple .rg files created
```

**Note:** Save/load times are higher than production because the test saves chunks individually, causing region file rewrites. Production batches saves for better performance.

### 3. Mob Lifecycle Worldtest

**File:** `crates/world/tests/mob_lifecycle_worldtest.rs`
**Duration:** ~11 seconds
**Scale:** 79,840 mobs across 625 chunks, 6,000 tick simulation

**What it validates:**
- Biome-appropriate mob spawning
- Mob AI state transitions
- Movement and wandering behavior
- Update performance at scale
- Long-running simulation stability

**Key metrics:**
- Total mobs spawned
- Avg update time per mob
- Movement statistics (distance traveled)
- AI state distribution
- P50/P95/P99 tick times

**When to run:**
- After mob AI changes
- After performance optimizations
- Before releases

**Expected results:**
```
Mobs spawned: 60k-80k
Update time: <1μs per mob
Movement: 100% of mobs moved
AI distribution: ~60-70% wandering
P99 tick: <5ms
```

### 4. Determinism Validation Worldtest

**File:** `crates/world/tests/determinism_worldtest.rs`
**Duration:** ~8 seconds
**Scale:** 289 chunks, 1,156 total regenerations

**What it validates:**
- Perfect voxel-level determinism
- Order-independent chunk generation
- Biome assignment consistency
- Heightmap reproducibility
- Multi-round regeneration stability

**Key metrics:**
- Voxel mismatches (must be 0)
- Biome consistency
- Heightmap consistency
- Multi-round verification

**When to run:**
- After ANY world generation changes
- After random number generation modifications
- Before every release (critical)

**Expected results:**
```
Voxel fidelity: 100.000000%
Biome mismatches: 0
Heightmap mismatches: 0
Round mismatches: 0
```

**Critical:** This test must always pass with zero mismatches. Any failure indicates a determinism break, which is a critical bug for multiplayer and replay systems.

### 5. Stage 4 Metrics Worldtest

**File:** `crates/world/tests/stage4_metrics_worldtest.rs`
**Duration:** ~2 seconds
**Scale:** 289 chunks (17×17 grid)

**What it validates:**
- All Stage 4 systems integration
- Metrics export functionality
- Complete system working together

**Key metrics:**
- All 8 metric types (terrain, lighting, mobs, items, rendering, network, persistence, execution)
- End-to-end system performance

**When to run:**
- After cross-system changes
- To validate metrics infrastructure
- For performance baselines

---

## Writing New Worldtests

### Structure Template

```rust
//! Brief Description Worldtest
//!
//! What this test validates (bullet points)

use mdminecraft_testkit::{
    MetricsReportBuilder, MetricsSink, TestResult,
    TerrainMetrics, TestExecutionMetrics,
};
use mdminecraft_world::{ /* imports */ };
use std::time::Instant;

const WORLD_SEED: u64 = /* unique seed */;
const CHUNK_RADIUS: i32 = /* test scale */;

#[test]
fn my_new_worldtest() {
    let test_start = Instant::now();

    println!("\n=== My New Worldtest ===");
    println!("Configuration:");
    println!("  World seed: {}", WORLD_SEED);
    println!();

    // Phase 1: Setup
    // ...

    // Phase 2: Main validation
    // ...

    // Phase 3: Metrics collection
    // ...

    // Build metrics report
    let test_duration = test_start.elapsed().as_secs_f64();
    let test_passed = /* validation logic */;

    let metrics = MetricsReportBuilder::new("my_new_worldtest")
        .result(if test_passed { TestResult::Pass } else { TestResult::Fail })
        .terrain(/* ... */)
        .execution(TestExecutionMetrics {
            duration_seconds: test_duration,
            peak_memory_mb: None,
            assertions_checked: Some(/* count */),
            validations_passed: Some(/* count */),
        })
        .build();

    // Write metrics
    let metrics_path = std::env::current_dir()
        .unwrap()
        .join("target/metrics/my_new_worldtest.json");

    let sink = MetricsSink::create(&metrics_path)
        .expect("Failed to create metrics sink");
    sink.write(&metrics).expect("Failed to write metrics");

    // Final results
    println!("=== Final Results ===");
    println!("Test result: {:?}", metrics.result);
    println!("Metrics: {:?}", metrics_path);

    // Assertions
    assert!(test_passed, "Test validation failed");
}
```

### Best Practices

1. **Naming:** Use `*_worldtest.rs` suffix for test files
2. **Documentation:** Include detailed header comments explaining what the test validates
3. **Phases:** Break test into logical phases with clear println! output
4. **Progress:** For long tests, show progress indicators
5. **Metrics:** Always export metrics for tracking
6. **Seeds:** Use unique world seeds per worldtest
7. **Cleanup:** Clean up temporary files (e.g., region files)
8. **Assertions:** Be specific in assertion messages

### Configuration Guidelines

**Scale Selection:**

| Purpose | Chunk Count | Grid Size | Duration Target |
|---------|-------------|-----------|-----------------|
| Smoke test | 1-25 | 1×1 to 5×5 | <1 second |
| Integration | 100-500 | 10×10 to 22×22 | 1-10 seconds |
| Large-scale | 1000-3000 | 31×31 to 54×54 | 10-30 seconds |
| Stress test | 5000+ | 70×70+ | 30+ seconds |

**Simulation Length:**

| Purpose | Ticks | Real Time (20 TPS) | Use Case |
|---------|-------|-------------------|----------|
| Quick validation | 100 | 5 seconds | Smoke tests |
| Short scenario | 1,200 | 1 minute | Basic behavior |
| Medium scenario | 6,000 | 5 minutes | Lifecycle tests |
| Long scenario | 24,000 | 20 minutes | Stress tests |

---

## Metrics Integration

### Metrics Schema

All worldtests export metrics in a standardized JSON format. See `crates/testkit/src/metrics.rs` for the schema.

**Core structure:**
```json
{
  "test_name": "my_worldtest",
  "timestamp": "2025-11-15T18:30:00Z",
  "result": "Pass",
  "terrain": { /* TerrainMetrics */ },
  "mobs": { /* MobMetrics */ },
  "test_execution": { /* TestExecutionMetrics */ }
}
```

### Metrics Location

All metrics are written to: `target/metrics/<test_name>.json`

### Reading Metrics

```rust
use mdminecraft_testkit::MetricsReport;
use std::fs;

let json = fs::read_to_string("target/metrics/my_worldtest.json")?;
let metrics: MetricsReport = serde_json::from_str(&json)?;

println!("Test result: {:?}", metrics.result);
if let Some(terrain) = &metrics.terrain {
    println!("Avg gen time: {:.2}ms", terrain.avg_gen_time_us / 1000.0);
}
```

### Comparing Metrics

For regression detection:

1. Save baseline metrics
2. Run tests after changes
3. Compare key metrics (see Performance Baselines doc)
4. Flag regressions >5% (warning) or >10% (failure)

---

## CI/CD Integration

### GitHub Actions Example

```yaml
name: Worldtests

on: [push, pull_request]

jobs:
  worldtests:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Install Rust
        uses: actions-rs/toolchain@v1
        with:
          toolchain: stable

      - name: Run worldtests
        run: cargo test --package mdminecraft-world --test '*worldtest' -- --nocapture

      - name: Upload metrics
        uses: actions/upload-artifact@v3
        with:
          name: worldtest-metrics
          path: target/metrics/*.json
```

### Metrics Tracking

1. Store metrics as CI artifacts
2. Use a tool like `metrics-diff` (to be implemented) to compare
3. Track historical performance in a database or dashboard

---

## Performance Expectations

See `wrk_docs/2025.11.15 - BAS - Performance Baselines.md` for detailed baselines.

### Quick Reference

| Metric | Baseline | Target | Status |
|--------|----------|--------|--------|
| Terrain gen (avg) | 4.4ms/chunk | <30ms | ✅ 6.8× faster |
| Mob update | 0.016μs | <1μs | ✅ 63× faster |
| Seam continuity | 100% | 100% | ✅ |
| Determinism | 100% | 100% | ✅ |
| Compression | 498× | >3× | ✅ 166× better |

### Regression Thresholds

- **5% degradation:** Warning (investigate)
- **10% degradation:** Failure (block merge)
- **Improvement:** Document and update baselines

---

## Troubleshooting

### Test Failures

**Determinism test fails:**
- Check for non-deterministic random number usage
- Verify no system time dependencies
- Ensure chunk generation is order-independent
- Check for floating-point non-determinism

**Persistence test fails:**
- Check region file permissions
- Verify temp directory is writable
- Ensure sufficient disk space
- Check for serialization bugs

**Performance regressions:**
- Run test multiple times to confirm
- Check for debug builds (use --release for accurate benchmarks)
- Profile using `cargo flamegraph`
- Compare against baseline metrics

### Common Issues

**Out of memory:**
```bash
# Reduce test scale or run sequentially
cargo test --test '*worldtest' -- --test-threads=1
```

**Timeout:**
```bash
# Increase timeout (default: 60s)
CARGO_TEST_TIMEOUT=600 cargo test --test large_scale_terrain_worldtest
```

**Metrics not exported:**
- Check that `target/metrics/` directory exists
- Verify write permissions
- Ensure test completed (didn't panic early)

**Flaky tests:**
- Verify determinism (same seed = same results)
- Check for race conditions in parallel code
- Ensure no external dependencies

---

## Additional Resources

- **Performance Baselines:** `wrk_docs/2025.11.15 - BAS - Performance Baselines.md`
- **Stage 5 Plan:** `wrk_docs/2025.11.15 - PLN - Stage 5 Hardening and Release Prep.md`
- **Metrics API:** `crates/testkit/src/metrics.rs`
- **Testkit Docs:** `crates/testkit/src/lib.rs`

---

## Appendix: Worldtest Comparison

| Aspect | Unit Test | Integration Test | Worldtest |
|--------|-----------|------------------|-----------|
| Scope | Single function/struct | 2-3 components | Entire subsystem |
| Duration | <1ms | 1ms-100ms | 1s-3min |
| Dependencies | None | Minimal | Full system |
| Parallelizable | Yes | Usually | Sometimes |
| GPU required | No | No | No |
| Metrics export | No | No | Yes |
| CI frequency | Every commit | Every commit | Daily/weekly |

---

**Document Version:** 1.0
**Last Updated:** 2025-11-15
**Maintained By:** Core development team
